{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Outline\n",
    "\n",
    "## Background:\n",
    "\n",
    "The marketing division of A Modern Bank has purchased data related to the number of reader comments on blog posts. We want to produce a quick prototype to understand the value of this data. You have been asked to present a business case to the Executive Manager of the marketing team.\n",
    "\n",
    "## Data:\n",
    "\n",
    "We will be using the ‘BlogFeedback’ dataset which can be downloaded here: https://archive.ics.uci.edu/ml/datasets/BlogFeedback\n",
    "\n",
    "A description of how the data was constructed and a data dictionary are available on this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Assumptions.\n",
    "\n",
    "I will assume the data set is \"relevant\". i.e that even if it is based on hungarian websites scraped in the early 2010's in real life, the features and descriptions websites are relevant to australia today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "url_orig = r\"https://archive.ics.uci.edu/ml/machine-learning-databases/00304/BlogFeedback.zip\"\n",
    "url = Path(url_orig)\n",
    "\n",
    "image_folder = Path('images')\n",
    "image_folder.mkdir(exist_ok=True)\n",
    "test_folder = Path('test')\n",
    "test_folder.mkdir(exist_ok=True)\n",
    "\n",
    "models_folder = Path('models')\n",
    "models_folder.mkdir(exist_ok=True)\n",
    "\n",
    "train_path_name = Path('blogData_train.csv')\n",
    "test_path_name = Path('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(url.name).exists():\n",
    "    req = requests.get(url_orig)\n",
    "    zip_name = url_orig.split('/')[-1]\n",
    "    with open(zip_name, 'wb') as zfile:\n",
    "        zfile.write(req.content)\n",
    "\n",
    "if not train_path_name.exists():\n",
    "    if not Path(url.name).exists():\n",
    "        pass\n",
    "        #response = requests.get(str(url))\n",
    "    zfile = ZipFile(url.name, 'r')\n",
    "    zfile.extract('blogData_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_path_name.exists():\n",
    "    if not Path(url.name).exists():\n",
    "        pass\n",
    "        #response = requests.get(str(url))\n",
    "    zfile = ZipFile(url.name, 'r')\n",
    "    for info in zfile.infolist():\n",
    "        if info.filename.startswith(\"blogData_test\"):\n",
    "            zfile.extract(info.filename, test_folder)\n",
    "    \n",
    "    chunks = []\n",
    "    for chunk in test_folder.glob('blogData_test*.csv'):\n",
    "        chunks += [pd.read_csv(chunk, header=None)]\n",
    "    test_data = pd.concat(chunks, ignore_index=True)\n",
    "    test_data.columns = ['Col_{}'.format(col+1) for col in test_data.columns]\n",
    "\n",
    "    \n",
    "    test_data.to_csv(test_path_name, index=False)\n",
    "test_df = pd.read_csv(test_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_1</th>\n",
       "      <th>Col_2</th>\n",
       "      <th>Col_3</th>\n",
       "      <th>Col_4</th>\n",
       "      <th>Col_5</th>\n",
       "      <th>Col_6</th>\n",
       "      <th>Col_7</th>\n",
       "      <th>Col_8</th>\n",
       "      <th>Col_9</th>\n",
       "      <th>Col_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col_272</th>\n",
       "      <th>Col_273</th>\n",
       "      <th>Col_274</th>\n",
       "      <th>Col_275</th>\n",
       "      <th>Col_276</th>\n",
       "      <th>Col_277</th>\n",
       "      <th>Col_278</th>\n",
       "      <th>Col_279</th>\n",
       "      <th>Col_280</th>\n",
       "      <th>Col_281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.630660</td>\n",
       "      <td>17.882992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.018276</td>\n",
       "      <td>10.396790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.435825</td>\n",
       "      <td>75.590485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.998589</td>\n",
       "      <td>44.560870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.733333</td>\n",
       "      <td>3.043390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.526070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.230215</td>\n",
       "      <td>45.970950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.784173</td>\n",
       "      <td>24.209942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>6.677075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7619</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7620</th>\n",
       "      <td>56.512093</td>\n",
       "      <td>77.442830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.296530</td>\n",
       "      <td>49.221344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7621</th>\n",
       "      <td>49.442368</td>\n",
       "      <td>112.620125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.445482</td>\n",
       "      <td>62.619390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>16.593575</td>\n",
       "      <td>19.671364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.512450</td>\n",
       "      <td>11.051215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7623</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7624 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col_1       Col_2  Col_3  Col_4  Col_5      Col_6      Col_7  Col_8  \\\n",
       "0     10.630660   17.882992    1.0  259.0    5.0   4.018276  10.396790    0.0   \n",
       "1     43.435825   75.590485    0.0  634.0   20.0  15.998589  44.560870    0.0   \n",
       "2      1.733333    3.043390    0.0    9.0    0.0   0.733333   1.526070    0.0   \n",
       "3     27.230215   45.970950    0.0  371.0   14.0  10.784173  24.209942    0.0   \n",
       "4      4.500000    6.677075    0.0   18.0    0.5   3.000000   4.000000    0.0   \n",
       "...         ...         ...    ...    ...    ...        ...        ...    ...   \n",
       "7619   0.000000    0.000000    0.0    0.0    0.0   0.000000   0.000000    0.0   \n",
       "7620  56.512093   77.442830    0.0  438.0   32.0  19.296530  49.221344    0.0   \n",
       "7621  49.442368  112.620125    1.0  849.0    9.0  20.445482  62.619390    0.0   \n",
       "7622  16.593575   19.671364    1.0  144.0   10.0   6.512450  11.051215    0.0   \n",
       "7623   0.000000    0.000000    0.0    0.0    0.0   0.000000   0.000000    0.0   \n",
       "\n",
       "      Col_9  Col_10  ...  Col_272  Col_273  Col_274  Col_275  Col_276  \\\n",
       "0     235.0     1.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "1     473.0     2.0  ...      0.0      0.0      0.0      0.0      1.0   \n",
       "2       5.0     0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "3     228.0     4.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "4      10.0     0.5  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "...     ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "7619    0.0     0.0  ...      1.0      0.0      0.0      0.0      0.0   \n",
       "7620  432.0     0.0  ...      0.0      1.0      0.0      0.0      0.0   \n",
       "7621  506.0     2.0  ...      1.0      0.0      0.0      0.0      0.0   \n",
       "7622  111.0     2.0  ...      0.0      0.0      1.0      0.0      0.0   \n",
       "7623    0.0     0.0  ...      0.0      0.0      1.0      0.0      0.0   \n",
       "\n",
       "      Col_277  Col_278  Col_279  Col_280  Col_281  \n",
       "0         0.0      0.0      0.0      0.0      4.0  \n",
       "1         0.0      0.0      0.0      0.0      0.0  \n",
       "2         0.0      0.0      0.0      0.0      1.0  \n",
       "3         0.0      0.0      0.0      0.0      5.0  \n",
       "4         0.0      0.0      0.0      0.0      0.0  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "7619      0.0      0.0      0.0      0.0      0.0  \n",
       "7620      0.0      0.0      0.0      0.0      0.0  \n",
       "7621      0.0      0.0      0.0      0.0      0.0  \n",
       "7622      0.0      0.0      0.0      0.0      3.0  \n",
       "7623      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[7624 rows x 281 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_1</th>\n",
       "      <th>Col_2</th>\n",
       "      <th>Col_3</th>\n",
       "      <th>Col_4</th>\n",
       "      <th>Col_5</th>\n",
       "      <th>Col_6</th>\n",
       "      <th>Col_7</th>\n",
       "      <th>Col_8</th>\n",
       "      <th>Col_9</th>\n",
       "      <th>Col_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col_272</th>\n",
       "      <th>Col_273</th>\n",
       "      <th>Col_274</th>\n",
       "      <th>Col_275</th>\n",
       "      <th>Col_276</th>\n",
       "      <th>Col_277</th>\n",
       "      <th>Col_278</th>\n",
       "      <th>Col_279</th>\n",
       "      <th>Col_280</th>\n",
       "      <th>Col_281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Col_1      Col_2  Col_3  Col_4  Col_5     Col_6     Col_7  Col_8  Col_9  \\\n",
       "0  40.30467  53.845657    0.0  401.0   15.0  15.52416  32.44188    0.0  377.0   \n",
       "1  40.30467  53.845657    0.0  401.0   15.0  15.52416  32.44188    0.0  377.0   \n",
       "2  40.30467  53.845657    0.0  401.0   15.0  15.52416  32.44188    0.0  377.0   \n",
       "3  40.30467  53.845657    0.0  401.0   15.0  15.52416  32.44188    0.0  377.0   \n",
       "4  40.30467  53.845657    0.0  401.0   15.0  15.52416  32.44188    0.0  377.0   \n",
       "\n",
       "   Col_10  ...  Col_272  Col_273  Col_274  Col_275  Col_276  Col_277  Col_278  \\\n",
       "0     3.0  ...      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     3.0  ...      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2     3.0  ...      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3     3.0  ...      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4     3.0  ...      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   Col_279  Col_280  Col_281  \n",
       "0      0.0      0.0      1.0  \n",
       "1      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0  \n",
       "3      0.0      0.0      1.0  \n",
       "4      0.0      0.0     27.0  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_path_name, header=None)\n",
    "\n",
    "df.columns = ['Col_{}'.format(col+1) for col in df.columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 13:25:15,853 - INFO     - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-05 13:25:15,858 - INFO     - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import dtale\n",
    "dtale.show(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute Information:\n",
    "\n",
    "\n",
    "\n",
    "1...50:\n",
    "Average, standard deviation, min, max and median of the\n",
    "Attributes 51...60 for the source of the current blog post\n",
    "With source we mean the blog on which the post appeared.\n",
    "For example, myblog.blog.org would be the source of\n",
    "the post myblog.blog.org/post_2010_09_10\n",
    "\n",
    "51: Total number of comments before basetime\n",
    "\n",
    "52: Number of comments in the last 24 hours before the\n",
    "basetime\n",
    "\n",
    "53: Let T1 denote the datetime 48 hours before basetime,\n",
    "Let T2 denote the datetime 24 hours before basetime.\n",
    "This attribute is the number of comments in the time period\n",
    "between T1 and T2\n",
    "\n",
    "54: Number of comments in the first 24 hours after the\n",
    "publication of the blog post, but before basetime\n",
    "\n",
    "55: The difference of Attribute 52 and Attribute 53\n",
    "56...60:\n",
    "The same features as the attributes 51...55, but\n",
    "features 56...60 refer to the number of links (trackbacks),\n",
    "while features 51...55 refer to the number of comments.\n",
    "\n",
    "61: The length of time between the publication of the blog post\n",
    "and basetime\n",
    "\n",
    "62: The length of the blog post\n",
    "\n",
    "63...262:\n",
    "The 200 bag of words features for 200 frequent words of the\n",
    "text of the blog post\n",
    "\n",
    "263...269: binary indicator features (0 or 1) for the weekday\n",
    "(Monday...Sunday) of the basetime\n",
    "\n",
    "270...276: binary indicator features (0 or 1) for the weekday\n",
    "(Monday...Sunday) of the date of publication of the blog\n",
    "post\n",
    "\n",
    "277: Number of parent pages: we consider a blog post P as a\n",
    "parent of blog post B, if B is a reply (trackback) to\n",
    "blog post P.\n",
    "\n",
    "278...280:\n",
    "Minimum, maximum, average number of comments that the\n",
    "parents received\n",
    "\n",
    "281: The target: the number of comments in the next 24 hours\n",
    "(relative to basetime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "Unfortunately it seems like the data has cleaned out some potentially useful features such as year, month. I suspect yearly, monthly (holidays school years) might be washing out some of the weekly trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes: \n",
    "Four columns are all zero. Perhaps missing and indicative of bad scrape/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df==0).all(0).astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable is int as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Col_281'] % 1 == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Col_281'] = df['Col_281'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distribution of the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Col_281\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.histplot(data=df, binwidth=100,\n",
    "             x=\"Col_281\", ax=ax)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Comments')\n",
    "ax.set_ylabel('Web Blogs')\n",
    "\n",
    "\n",
    "from matplotlib.ticker import StrMethodFormatter, NullFormatter\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))\n",
    "\n",
    "\n",
    "plt.savefig(str(Path('Images') / 'Distribution_of_Comment_Counts.svg'))\n",
    "plt.show()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note this might suggest exponatial distributional possibly need poisson regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count_bin = Counter(df[\"Col_281\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bin[0], count_bin[1], count_bin[2], count_bin[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations in predictors\n",
    "\n",
    "This might help us think about what a linear regressor would do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "correlations = df.corr()\n",
    "# mask = np.triu(np.ones_like(correlations, dtype=bool))\n",
    "sns.heatmap(correlations, ax=ax)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "As expected the stat features like mean median etc highly correlated with each other. \n",
    "\n",
    "The \"bag of words\", 63...262, are alo highly correlated with each other.\n",
    "\n",
    "#### Look at which correlate with the predictor Col_281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "sns.heatmap(correlations[-1:], ax=ax, cmap =sns.color_palette(\"viridis\", as_cmap=True) )\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "It looks like strongest influences are the popularity of the web blog.\n",
    "\n",
    "#### Comment out and in the m, n range you'd like to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = 0, 50 # basetime stats, Average, standard deviation, min, max and median \n",
    "# m, n = 269, 276 # Publish dates\n",
    "# m, n = 63, 262 # 'Bag of words' Features\n",
    "m, n = 263, 280 # Seems empty.\n",
    "\n",
    "\n",
    "cols = list(range(m, n)) + [280]\n",
    "sub_corr = correlations.iloc[cols, cols]\n",
    "#mask=None\n",
    "mask = np.triu(np.ones_like(sub_corr, dtype=bool))\n",
    "sns.heatmap(sub_corr, mask=mask, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "sns.heatmap(sub_corr[-1:], ax=ax, cmap = sns.color_palette(\"viridis\", as_cmap=True))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Most Common day of publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_day_df = df.iloc[:, 269:276].astype(int)\n",
    "publication_day_df.columns = ['Mon', \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "count_publication_df = publication_day_df.sum()\n",
    "count_publication_df.plot(ax=ax)\n",
    "ax.set_ylabel('Web Posts')\n",
    "ax.set_xlabel('Publish Day')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(image_folder/ 'Publishing Days.svg' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = pd.DataFrame()\n",
    "for col in publication_day_df:\n",
    "    count_cols[col] = publication_day_df[col]*df.iloc[:, -1]\n",
    "count_cols = count_cols.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "count_cols.plot(ax=ax)\n",
    "ax.set_ylabel('Comments on Post')\n",
    "ax.set_xlabel('Publish Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "(count_cols/count_publication_df).plot(ax=ax)\n",
    "ax.set_ylabel('Comments Per Web Blog Post')\n",
    "ax.set_xlabel('Publish Day')\n",
    "\n",
    "y_min, y_max = ax.get_ylim()\n",
    "ax.set_ylim(y_min/2, y_max*1.2)\n",
    "\n",
    "fig.savefig(image_folder/ 'Replies per post Days.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(models_folder.glob(\"*.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:, 0:-2]\n",
    "target = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise Data\n",
    "First we're going to standardise. \n",
    "\n",
    "Recall\n",
    "\n",
    "263...269: binary indicator features (0 or 1) for the weekday\n",
    "(Monday...Sunday) of the basetime\n",
    "\n",
    "270...276: binary indicator features (0 or 1) for the weekday\n",
    "(Monday...Sunday) of the date of publication of the blog\n",
    "post\n",
    "\n",
    "We're going to not scaled this since they're True and False. We will also get rid of monday since that we need 6 indicators to represent 7 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary features are day of publish and Basetime\n",
    "categorical_columns = [\"Col_{}\".format(n) for n in range(263, 277)]\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = df.iloc[:, 0:-1]\n",
    "\n",
    "# Binary features are day of publish and Basetime\n",
    "def prepare_data(raw_data, categorical_columns, transformer)\n",
    "    categorical_features = data[[col for col in categorical_columns if col not in [\"Col_263\", \"Col_270\"]]]\n",
    "    features = data[[col for col in data.columns if col not in categorical_columns]]\n",
    "    \n",
    "    data = features.merge(categorical_features, left_index=True, right_index=True, validate='1:1')\n",
    "    assert data.shape[0] == raw_data.shape[0]\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    \n",
    "data = prepare_data(raw_data, categorical_columns\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.merge(categorical_features, left_index=True, right_index=True, validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model\n",
    "Try to predict the number of comments recieved in 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'basic_linear_model'\n",
    "\n",
    "model = LinearRegression().fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.score(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...meh..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the largest positive factor to the model is column index 17... or Col_18. Col 18 Corresponds to the minumum of the of \"Number of comments in the first 24 hours after the publication of the blog post for a web blog. We can infer this looking at the correlation plots. data isn't standardsided..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.regplot(x=df['Col_18'], y=df['Col_281'], ax=ax)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Col 18 looks digitised because at tail end there must be few Blogs with multiple posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_[262:269]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_[270:276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 270:276].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.iloc[:, 0:-2]\n",
    "test_target = test_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(test, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "My pc runs out of memory if I try to generate interaction features in the data...could try dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 Logistic Model\n",
    "\n",
    "Predict \"significant\" activity. i.e. Web blogs with comments above N.\n",
    "\n",
    "Use logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "N = 1\n",
    "class_target = (target > N-1).astype(int) # I.e. Active Blogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_model = LogisticRegression(max_iter=30000, solver='lbfgs').fit(data, class_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_model.score(data, class_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(class_target, logi_model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(class_target, logi_model.predict(data)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[tn,  ]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(class_target, logi_model.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logi_model.predict(data).astype(bool)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = class_target.values.astype(bool)\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = predict & actual\n",
    "print(true_positive)\n",
    "true_positves = true_positive.sum()\n",
    "print(true_positves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = predict & ~actual\n",
    "print(false_positive)\n",
    "false_positives = false_positive.sum()\n",
    "print(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative = ~predict & ~actual\n",
    "print(true_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.iloc[:, 0:-2]\n",
    "test_target = test_df.iloc[:, -1]\n",
    "\n",
    "class_target_test = (test_target > N-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logi_model.score(test, class_target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "When I tested N=100 I got near .99 overall f1, likely spurious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(class_target_test, logi_model.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will more data help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn max iter down if taking too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 10000\n",
    "#logi_model_100 = LogisticRegression(max_iter=10000).fit(data[:100], class_target[:100])\n",
    "logi_model_1000 = LogisticRegression(max_iter=max_iter).fit(data[:1000], class_target[:1000])\n",
    "logi_model_5000 = LogisticRegression(max_iter=max_iter).fit(data[:5000], class_target[:5000])\n",
    "logi_model_10k = LogisticRegression(max_iter=max_iter).fit(data[:10000], class_target[:10000])\n",
    "logi_model_20k = LogisticRegression(max_iter=max_iter).fit(data[:20000], class_target[:20000])\n",
    "logi_model_50k = LogisticRegression(max_iter=max_iter).fit(data[:50000], class_target[:50000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Lot's of warnings about convergence. Current data is mix of categorical flags and numerical can optimise later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vals = [#logi_model_100.score(test, class_target_test),\n",
    "          logi_model_1000.score(test, class_target_test),\n",
    "          logi_model_5000.score(test, class_target_test),\n",
    "          logi_model_10k.score(test, class_target_test),\n",
    "          logi_model_20k.score(test, class_target_test),\n",
    "          logi_model_50k.score(test, class_target_test),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = plt.plot(r_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "Increasing the training set size *seems* to help... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 3\n",
    "\n",
    "rando forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
